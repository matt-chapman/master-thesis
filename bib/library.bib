Automatically generated by Mendeley Desktop 1.17.9
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Haynes2014,
abstract = {In the multiple changepoint setting, various search methods have been proposed which involve optimising either a constrained or penalised cost function over possible numbers and locations of changepoints using dynamic programming. Such methods are typically computationally intensive. Recent work in the penalised optimisation setting has focussed on developing a pruning-based approach which gives an improved computational cost that, under certain conditions, is linear in the number of data points. Such an approach naturally requires the specification of a penalty to avoid under/over-fitting. Work has been undertaken to identify the appropriate penalty choice for data generating processes with known distributional form, but in many applications the model assumed for the data is not correct and these penalty choices are not always appropriate. Consequently it is desirable to have an approach that enables us to compare segmentations for different choices of penalty. To this end we present a method to obtain optimal changepoint segmentations of data sequences for all penalty values across a continuous range. This permits an evaluation of the various segmentations to identify a suitably parsimonious penalty choice. The computational complexity of this approach can be linear in the number of data points and linear in the difference between the number of changepoints in the optimal segmentations for the smallest and largest penalty values. This can be orders of magnitude faster than alternative approaches that find optimal segmentations for a range of the number of changepoints.},
archivePrefix = {arXiv},
arxivId = {1412.3617},
author = {Haynes, Kaylea and Eckley, Idris A. and Fearnhead, Paul},
eprint = {1412.3617},
file = {:Users/matt/Documents/Mendeley Desktop/Haynes, Eckley, Fearnhead - 2014 - Efficient penalty search for multiple changepoint problems.pdf:pdf},
keywords = {dynamic programming,penalised likelihood,segmenta-,structural change},
pages = {1--23},
title = {{Efficient penalty search for multiple changepoint problems}},
url = {http://arxiv.org/abs/1412.3617},
year = {2014}
}
@article{Ginsberg2009,
abstract = {Seasonal influenza epidemics are a major public health concern, causing tens of millions of respiratory illnesses and 250,000 to 500,000 deaths worldwide each year. In addition to seasonal influenza, a new strain of influenza virus against which no previous immunity exists and that demonstrates human-to-human transmission could result in a pandemic with millions of fatalities. Early detection of disease activity, when followed by a rapid response, can reduce the impact of both seasonal and pandemic influenza. One way to improve early detection is to monitor health-seeking behaviour in the form of queries to online search engines, which are submitted by millions of users around the world each day. Here we present a method of analysing large numbers of Google search queries to track influenza-like illness in a population. Because the relative frequency of certain queries is highly correlated with the percentage of physician visits in which a patient presents with influenza-like symptoms, we can accurately estimate the current level of weekly influenza activity in each region of the United States, with a reporting lag of about one day. This approach may make it possible to use search queries to detect influenza epidemics in areas with a large population of web search users.},
author = {Ginsberg, Jeremy and Mohebbi, Matthew H and Patel, Rajan S and Brammer, Lynnette and Smolinski, Mark S and Brilliant, Larry},
doi = {10.1038/nature07634},
file = {:Users/matt/Documents/Mendeley Desktop/Ginsberg et al. - 2009 - Detecting influenza epidemics using search engine query data.pdf:pdf},
isbn = {1476-4687 (Electronic)},
issn = {1476-4687},
journal = {Nature},
keywords = {Centers for Disease Control and Prevention (U.S.),Databases, Factual,Health Behavior,Health Education,Health Education: statistics {\&} numerical data,Humans,Influenza, Human,Influenza, Human: diagnosis,Influenza, Human: epidemiology,Influenza, Human: transmission,Influenza, Human: virology,Internationality,Internet,Internet: utilization,Linear Models,Office Visits,Office Visits: statistics {\&} numerical data,Population Surveillance,Population Surveillance: methods,Reproducibility of Results,Seasons,Time Factors,United States,User-Computer Interface},
number = {7232},
pages = {1012--4},
pmid = {19020500},
title = {{Detecting influenza epidemics using search engine query data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19020500},
volume = {457},
year = {2009}
}
@article{Qahtan2015,
abstract = {Detecting changes in multidimensional data streams is an important and challenging task. In unsupervised change detection, changes are usually detected by comparing the distribution in a current (test) window with a reference window. It is thus essential to design divergence metrics and density estimators for comparing the data distributions, which are mostly done for univariate data. Detecting changes in multidimensional data streams brings difficulties to the density estimation and comparisons. In this paper, we propose a framework for detecting changes in multidimensional data streams based on principal component analysis, which is used for project-ing data into a lower dimensional space, thus facilitating density estimation and change-score calculations. The proposed frame-work also has advantages over existing approaches by reducing computational costs with an efficient density estimator, promoting the change-score calculation by introducing effective divergence metrics, and by minimizing the efforts required from users on the threshold parameter setting by using the Page-Hinkley test. The evaluation results on synthetic and real data show that our frame-work outperforms two baseline methods in terms of both detection accuracy and computational costs.},
author = {Qahtan, Abdulhakim A. and Alharbi, Basma and Wang, Suojin and Zhang, Xiangliang},
doi = {10.1145/2783258.2783359},
file = {:Users/matt/Documents/Mendeley Desktop/Qahtan et al. - 2015 - A PCA-Based Change Detection Framework for Multidimensional Data Streams.pdf:pdf},
isbn = {9781450336642},
journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15},
keywords = {change detection,data streams,density estimation,principal component analysis},
pages = {935--944},
title = {{A PCA-Based Change Detection Framework for Multidimensional Data Streams}},
url = {http://dl.acm.org/citation.cfm?id=2783258.2783359},
year = {2015}
}
@article{Killick2014,
abstract = {One of the key challenges in changepoint analysis is the ability to detect multiple changes within a given time series or sequence. The changepoint package has been developed to provide users with a choice of multiple changepoint search methods to use in conjunction with a given changepoint method and in particular provides an implementation of the recently proposed PELT algorithm. This article describes the search methods which are implemented in the package as well as some of the available test statistics whilst highlighting their application with simulated and practical examples. Particular emphasis is placed on the PELT algorithm and how results differ from the binary segmentation approach.},
author = {Killick, Rebecca and Eckley, Idris A.},
doi = {10.18637/jss.v058.i03},
file = {:Users/matt/Documents/Mendeley Desktop/Killick, Eckley - 2014 - changepoint An R Package for Changepoint Analysis.pdf:pdf},
journal = {Journal of Statistical Software},
number = {3},
pages = {1--19},
title = {{changepoint: An R Package for Changepoint Analysis}},
url = {http://www.jstatsoft.org/v58/i03/},
volume = {58},
year = {2014}
}
@article{Xu2011,
author = {Xu, Yi and Zhang, Zhongfei and Yu, Philips and Long, Bo},
doi = {10.1145/2063576.2063735},
file = {:Users/matt/Documents/Mendeley Desktop/Xu et al. - 2011 - Pattern change discovery between high dimensional data sets.pdf:pdf},
isbn = {9781450307178},
journal = {Proceedings of the 20th ACM international conference on Information and knowledge management - CIKM '11},
keywords = {ma-,mapping,pal angles,pattern change detection,princi-,principle of dominant subspace,unsupervised learning},
pages = {1097},
title = {{Pattern change discovery between high dimensional data sets}},
url = {http://dl.acm.org/citation.cfm?doid=2063576.2063735},
year = {2011}
}
@article{Siegmund1995,
abstract = {We study sequential detection of a change-point using the generalized likelihood ratio statistic. For the special case of detecting a change in a normal mean with known variance, we give approximations to the average run lengths and compare our procedure to standard CUSUM tests and combined CUSUM-Shewhart tests. Several examples indicating extensions to problems involving multiple parameters are discussed.},
author = {Siegmund, D. and Venkatraman, E. S.},
doi = {10.1214/aos/1176324466},
file = {:Users/matt/Documents/Mendeley Desktop/Siegmund, Venkatraman - 1995 - Using the generalized likelihood ratio statistic for sequential detection of a change-point.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
number = {1},
pages = {255--271},
title = {{Using the generalized likelihood ratio statistic for sequential detection of a change-point}},
volume = {23},
year = {1995}
}
@article{Matteson2012,
abstract = {Change point analysis has applications in a wide variety of fields. The general problem concerns the inference of a change in distribution for a set of time-ordered observations. Sequential detection is an online version in which new data is continually arriving and is analyzed adaptively. We are concerned with the related, but distinct, offline version, in which retrospective analysis of an entire sequence is performed. For a set of multivariate observations of arbitrary dimension, we consider nonparametric estimation of both the number of change points and the positions at which they occur. We do not make any assumptions regarding the nature of the change in distribution or any distribution assumptions beyond the existence of the $\alpha$th absolute moment, for some $\alpha$ ∈ (0,2). Estimation is based on hierarchical clustering and we propose both divisive and agglomerative algorithms. The divisive method is shown to provide consistent estimates of both the number and location of change points under standard regularity assumptions. We compare the proposed approach with competing methods in a simulation study. Methods from cluster analysis are applied to assess performance and to allow simple comparisons of location estimates, even when the estimated number differs. We conclude with applications in genetics, finance and spatio-temporal analysis.},
archivePrefix = {arXiv},
arxivId = {1306.4933},
author = {Matteson, David S. and James, Nicholas A.},
doi = {10.1080/01621459.2013.849605},
eprint = {1306.4933},
file = {:Users/matt/Documents/Mendeley Desktop/Matteson, James - 2012 - A nonparametric approach for multiple change point analysis of multivariate data.pdf:pdf},
issn = {0162-1459},
journal = {Submitted},
keywords = {cluster analysis,multivariate time series,permutation tests,signal processing},
pages = {1--29},
title = {{A nonparametric approach for multiple change point analysis of multivariate data}},
volume = {14853},
year = {2012}
}
@article{Kawahara2009,
author = {Kawahara, Yoshinobu and Sugiyama, Masashi},
file = {:Users/matt/Documents/Mendeley Desktop/Kawahara, Sugiyama - 2009 - Change-point detection in time-series data by direct density-ratio estimation.pdf:pdf},
journal = {Proceedings of the 2009 SIAM International Conference on Data Mining},
keywords = {change-point detection,direct density-ratio,estimation,kernel methods,time-series data},
pages = {389--400},
title = {{Change-point detection in time-series data by direct density-ratio estimation}},
year = {2009}
}
@article{Fawcett1999,
abstract = {We introduce a problem class which we term activity monitoring. Such problems involve monitoring the behavior of a large population of entities for interesting events requiring action. We present a framework within which each of the individual problems has a natural expression, as well as a methodology for evaluating performance of activity monitoring techniques. We show that two superficially different tasks, news story monitoring and intrusion detection, can be expressed naturally within the...},
author = {Fawcett, Tom and Provost, Foster},
doi = {10.1016/j.ecoleng.2010.11.031},
file = {:Users/matt/Documents/Mendeley Desktop/Fawcett, Provost - 1999 - Activity monitoring Noticing interesting changes in behavior.pdf:pdf},
isbn = {1581131437},
issn = {09258574},
journal = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining},
number = {212},
pages = {53--62},
title = {{Activity monitoring: Noticing interesting changes in behavior}},
url = {http://portal.acm.org/citation.cfm?id=312195},
volume = {1},
year = {1999}
}
@book{Wickham2009,
abstract = {This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkison's Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, it's easy to:produce handsome, publication-quality plots, with automatic legends created from the plot specificationsuperpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scalesadd customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regressionsave any ggplot2 plot (or part thereof) for later modification or reusecreate custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plotsapproach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot.This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and you'll learn everything you need in the book. After reading this book you'll be able to produce graphics customized precisely for your problems, to and you'll find it easy to get graphics out of your head and on to the screen or page.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Wickham, Hadley},
booktitle = {Media},
doi = {10.1007/978-0-387-98141-3},
eprint = {arXiv:1011.1669v3},
isbn = {9780387981406},
issn = {0006341X},
number = {July},
pages = {211},
pmid = {19791908},
publisher = {Springer-Verlag New York},
title = {{Elegant Graphics for Data Analysis}},
url = {http://had.co.nz/ggplot2/book},
volume = {35},
year = {2009}
}
@article{Pelecanos2010,
abstract = {Detection of outbreaks is an important part of disease surveillance. Although many algorithms have been designed for detecting outbreaks, few have been specifically assessed against diseases that have distinct seasonal incidence patterns, such as those caused by vector-borne pathogens.},
author = {Pelecanos, Anita M and Ryan, Peter a and Gatton, Michelle L},
doi = {10.1186/1472-6947-10-74},
file = {:Users/matt/Documents/Mendeley Desktop/Pelecanos, Ryan, Gatton - 2010 - Outbreak detection algorithms for seasonal disease data a case study using Ross River virus disease.pdf:pdf},
issn = {1472-6947},
journal = {BMC medical informatics and decision making},
number = {1},
pages = {74},
pmid = {21106104},
title = {{Outbreak detection algorithms for seasonal disease data: a case study using Ross River virus disease.}},
url = {http://www.biomedcentral.com/1472-6947/10/74},
volume = {10},
year = {2010}
}
@article{Akoglu2013,
abstract = {Detecting anomalies and events in data is a vital task, with numerous applications in security, finance, health care, law enforcement, and many others. While many techniques have been developed in past years for spotting outliers and anomalies in unstructured collections of multi-dimensional points, with graph data becoming ubiquitous, techniques for structured graph data have been of focus recently. As objects in graphs have long-range correlations, novel technology has been developed for abnormality detection in graph data. The goal of this tutorial is to provide a general, comprehensive overview of the state-of-the-art methods for anomaly, event, and fraud detection in data represented as graphs. As a key contribution, we provide a thorough exploration of both data mining and machine learning algorithms for these detection tasks. We give a general framework for the algorithms, categorized under various settings: unsupervised vs.(semi-)supervised, for static vs. dynamic data. We focus on the scalability and effectiveness aspects of the methods, and highlight results on crucial real-world applications, including accounting fraud and opinion spam detection.},
author = {Akoglu, Leman and Faloutsos, Christos},
doi = {10.1145/2433396.2433496},
file = {:Users/matt/Documents/Mendeley Desktop/Akoglu, Faloutsos - 2013 - Anomaly, event, and fraud detection in large network datasets.pdf:pdf},
isbn = {9781450318693},
journal = {Proceedings of the sixth ACM international conference on Web search and data mining - WSDM '13},
keywords = {anomaly detection,event detection,fraud,graph mining},
pages = {773},
title = {{Anomaly, event, and fraud detection in large network datasets}},
url = {http://dl.acm.org/citation.cfm?id=2433396.2433496},
year = {2013}
}
@article{Lai1999,
abstract = {This paper addresses a number of open problems concerning the$\backslash$ngeneralized likelihood ratio (GLR) rules for online detection of faults$\backslash$nand parameter changes in control systems. It is shown that with an$\backslash$nappropriate choice of the threshold and window size, these GLR rules are$\backslash$nasymptotically optimal. The rules are also extended to non-likelihood$\backslash$nstatistics that are widely used in monitoring adaptive algorithms for$\backslash$nsystem identification and control by establishing Gaussian$\backslash$napproximations to these statistics when the window size is chosen$\backslash$nsuitably. Recursive algorithms are developed for practical$\backslash$nimplementation of the procedure, and importance sampling techniques are$\backslash$nintroduced for determining the threshold of the rule to satisfy$\backslash$nprescribed bounds on the false alarm rate},
author = {Lai, Tze Leung and Shan, Jerry Zhaolin},
doi = {10.1109/9.763211},
file = {:Users/matt/Documents/Mendeley Desktop/Lai, Shan - 1999 - Efficient recursive algorithms for detection of abrupt changes in signals and control systems.pdf:pdf},
isbn = {0018-9286},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
number = {5},
pages = {952--966},
title = {{Efficient recursive algorithms for detection of abrupt changes in signals and control systems}},
volume = {44},
year = {1999}
}
@unpublished{Madrid2004,
author = {Galeano, Pedro and Pe{\~{n}}a, Daniel},
file = {:Users/matt/Documents/Mendeley Desktop/Madrid et al. - 2004 - Variance Changes Detection in Multivariate Time Series.pdf:pdf},
keywords = {heteroskedasticity,likelihood ratio test statistic,step changes,varma models},
title = {{Variance Changes Detection in Multivariate Time Series}},
year = {2004}
}
@article{Amigo2009,
abstract = {There is a wide set of evaluation metrics available to compare the quality of text clustering algorithms. In this article, we define a few intuitive formal constraints on such metrics which shed light on which aspects of the quality of a clustering are captured by different metric families. These formal constraints are validated in an experiment involving human assessments, and compared with other constraints proposed in the literature. Our analysis of a wide range of metrics shows that only BCubed satisfies all formal constraints. We also extend the analysis to the problem of overlapping clustering, where items can simultaneously belong to more than one cluster. As Bcubed cannot be directly applied to this task, we propose a modified version of Bcubed that avoids the problems found with other metrics.},
author = {Amig{\'{o}}, Enrique and Gonzalo, Julio and Artiles, Javier and Verdejo, Felisa},
doi = {10.1007/s10791-008-9066-8},
file = {:Users/matt/Documents/Mendeley Desktop/Amig{\'{o}} et al. - 2009 - A comparison of extrinsic clustering evaluation metrics based on formal constraints.pdf:pdf},
isbn = {1386-4564 (Print) 1573-7659 (Online)},
issn = {13864564},
journal = {Information Retrieval},
keywords = {Clustering,Evaluation metrics,Formal constraints},
number = {4},
pages = {461--486},
title = {{A comparison of extrinsic clustering evaluation metrics based on formal constraints}},
volume = {12},
year = {2009}
}
@article{Willsky1976,
abstract = {We consider a class of stochastic linear systems that are subject to jumps of unknown magnitudes in the state variables occurring at unknown times. This model can be used when considering such problems as estimation for systems subject to possible component failures and the tracking of vehicles capable of abrupt maneuvers. Using Kalman-Bucy filtering and generalized likelihood ratio techniques, we devise an adaptive filtering system for the detection and estimation of the jumps. An example that illustrates the dynamical properties of our filtering scheme is discusssed in detail.},
author = {Willsky, Alan S. and Jones, Harold L.},
doi = {10.1109/TAC.1976.1101146},
file = {:Users/matt/Documents/Mendeley Desktop/Willsky, Jones - 1976 - A Generalized Likelihood Ratio Approach to the Detection and Estimation of Jumps in Linear Systems.pdf:pdf},
isbn = {0018-9286},
issn = {15582523},
journal = {IEEE Transactions on Automatic Control},
number = {1},
pages = {108--112},
title = {{A Generalized Likelihood Ratio Approach to the Detection and Estimation of Jumps in Linear Systems}},
volume = {21},
year = {1976}
}
@article{Alvanaki2011,
abstract = {1 Hila Becker, Mor Naaman, and Luis Gravano. Learning similarity metrics for event identification in social media. WSDM, 2010. 2 Manish Bhide, Venkatesan T. Chakaravarthy, Krithi Ramamritham, and Prasan Roy. Keyword search over dynamic categorized information. ICDE, 2009.},
author = {Alvanaki, Foteini and Michel, Sebastian and Ramamritham, Krithi and Weikum, Gerhard},
doi = {10.1145/1989323.1989473},
file = {:Users/matt/Documents/Mendeley Desktop/Alvanaki et al. - 2011 - EnBlogue emergent topic detection in Web 2.0 streams.pdf:pdf},
isbn = {9781450306614},
issn = {07308078},
journal = {Proc. ACM SIGMOD International Conference on Management of Data},
keywords = {Social networks,Web},
pages = {1271--1274},
title = {{EnBlogue: emergent topic detection in Web 2.0 streams}},
url = {http://doi.acm.org/10.1145/1989323.1989473{\%}5Cnpapers2://publication/uuid/44E009D1-8574-49C1-A0AC-C2B247FE9043},
year = {2011}
}
@inproceedings{Buntain2014,
author = {Buntain, Cody and Natoli, Christopher and Zivkovic, Miroslav},
booktitle = {Supercomputing},
file = {:Users/matt/Documents/Mendeley Desktop/Buntain, Natoli - Unknown - A Brief Comparison of Algorithms for Detecting Change Points in Data.pdf:pdf},
title = {{A Brief Comparison of Algorithms for Detecting Change Points in Data}},
url = {https://github.com/cbuntain/ChangePointDetection},
year = {2014}
}
@article{Dasu2009,
abstract = {Data streams are dynamic, with frequent distributional changes. In this paper, we propose a statistical approach to detecting distributional shifts in multi-dimensional data streams. We use relative entropy, also known as the Kullback-Leibler distance, to measure the statistical distance between two distributions. In the context of a multi-dimensional data stream, the distributions are generated by data from two sliding windows. We maintain a sample of the data from the stream inside the windows to build the distributions. Our algorithm is streaming, nonparametric, and requires no distributional or model assumptions. It employs the statistical theory of hypothesis testing and bootstrapping to determine whether the distributions are statistically different. We provide a full suite of experiments on synthetic data to validate the method and demonstrate its effectiveness on data from real-life applications. {\textcopyright} 2009 Springer Berlin Heidelberg.},
author = {Dasu, Tamraparni and Krishnan, Shankar and Lin, Dongyu and Venkatasubramanian, Suresh and Yi, Kevin},
doi = {10.1007/978-3-642-03915-7_3},
file = {:Users/matt/Documents/Mendeley Desktop/Dasu et al. - 2009 - Change (detection) you can believe in Finding distributional shifts in data streams.pdf:pdf},
isbn = {3642039146},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {21--34},
title = {{Change (detection) you can believe in: Finding distributional shifts in data streams}},
volume = {5772 LCNS},
year = {2009}
}
@article{Tran2014,
abstract = {Big Data is identified by its three Vs, namely velocity, volume, and variety. The area of data stream processing has long dealt with the former two Vs velocity and volume. Over a decade of intensive research, the community has provided many important research discoveries in the area. The third V of Big Data has been the result of social media and the large unstructured data it generates. Streaming techniques have also been proposed re-cently addressing this emerging need. However, a hidden factor can represent an important fourth V, that is variability or change. Our world is changing rapidly, and accounting to variability is a crucial success factor. This paper provides a survey of change detection techniques as applied to streaming data. The review is timely with the rise of Big Data technologies, and the need to have this important aspect highlighted and its techniques catego-rized and detailed.},
author = {Tran, Dang-Hoan and Gaber, Mohamed Medhat and Sattler, Kai-Uwe},
doi = {10.1145/2674026.2674031},
file = {:Users/matt/Documents/Mendeley Desktop/Tran, Gaber, Sattler - 2014 - Change Detection in Streaming Data in the Era of Big Data Models and Issues.pdf:pdf},
isbn = {1931-0145},
issn = {1931-0145},
journal = {ACM SIGKDD Explorations Newsletter - Special issue on big data},
number = {1},
pages = {30--38},
title = {{Change Detection in Streaming Data in the Era of Big Data: Models and Issues}},
year = {2014}
}
@article{Kulldorff2005,
abstract = {BACKGROUND: The ability to detect disease outbreaks early is important in order to minimize morbidity and mortality through timely implementation of disease prevention and control measures. Many national, state, and local health departments are launching disease surveillance systems with daily analyses of hospital emergency department visits, ambulance dispatch calls, or pharmacy sales for which population-at-risk information is unavailable or irrelevant. METHODS AND FINDINGS: We propose a prospective space-time permutation scan statistic for the early detection of disease outbreaks that uses only case numbers, with no need for population-at-risk data. It makes minimal assumptions about the time, geographical location, or size of the outbreak, and it adjusts for natural purely spatial and purely temporal variation. The new method was evaluated using daily analyses of hospital emergency department visits in New York City. Four of the five strongest signals were likely local precursors to citywide outbreaks due to rotavirus, norovirus, and influenza. The number of false signals was at most modest. CONCLUSION: If such results hold up over longer study times and in other locations, the space-time permutation scan statistic will be an important tool for local and national health departments that are setting up early disease detection surveillance systems.},
author = {Kulldorff, Martin and Heffernan, Richard and Hartman, Jessica and Assun????o, Renato and Mostashari, Farzad},
doi = {10.1371/journal.pmed.0020059},
file = {:Users/matt/Documents/Mendeley Desktop/Kulldorff et al. - 2005 - A space-time permutation scan statistic for disease outbreak detection.PDF:PDF},
isbn = {1549-1676 (Electronic)$\backslash$n1549-1277 (Linking)},
issn = {15491277},
journal = {PLoS Medicine},
number = {3},
pages = {0216--0224},
pmid = {15719066},
title = {{A space-time permutation scan statistic for disease outbreak detection}},
volume = {2},
year = {2005}
}
@article{Kifer2004,
abstract = {Detecting changes in a data stream is an im- portant area of research with many appli- cations. In this paper, we present a novel method for the detection and estimation of change. In addition to providing statisti- cal guarantees on the reliability of detected changes, our method also provides meaning- ful descriptions and quantification of these changes. Our approach assumes that the points in the stream are independently gen- erated, but otherwise makes no assumptions on the nature of the generating distribution. Thus our techniques work for both continuous and discrete data. In an experimental study we demonstrate the power of our techniques.},
archivePrefix = {arXiv},
arxivId = {cond-mat/9310008},
author = {Kifer, Daniel and Ben-david, Shai and Gehrke, Johannes},
doi = {10.1016/0378-4371(94)90421-9},
eprint = {9310008},
file = {:Users/matt/Documents/Mendeley Desktop/Kifer, Ben-david, Gehrke - 2004 - Detecting Change in Data Streams.PDF:PDF},
isbn = {0120884690},
issn = {00394564},
journal = {Proceedings of the 30th VLDB Conference},
pages = {180--191},
pmid = {1631915},
primaryClass = {cond-mat},
title = {{Detecting Change in Data Streams}},
year = {2004}
}
@article{Desobry2005,
abstract = {A number of abrupt change detection methods have been proposed in the past, among which are efficient model-based techniques such as the Generalized Likelihood Ratio (GLR) test. We consider the case where no accurate nor tractable model can be found, using a model-free approach, called Kernel change detection (KCD). KCD compares two sets of descriptors extracted online from the signal at each time instant: The immediate past set and the immediate future set. Based on the soft margin single-class Support Vector Machine (SVM), we build a dissimilarity measure in feature space between those sets, without estimating densities as an intermediary step. This dissimilarity measure is shown to be asymptotically equivalent to the Fisher ratio in the Gaussian case. Implementation issues are addressed; in particular, the dissimilarity measure can be computed online in input space. Simulation results on both synthetic signals and real music signals show the efficiency of KCD.},
author = {Desobry, Fr{\'{e}}d{\'{e}}ric and Davy, Manuel and Doncarli, Christian},
doi = {10.1109/TSP.2005.851098},
file = {:Users/matt/Documents/Mendeley Desktop/Desobry, Davy, Doncarli - 2005 - An online Kernel change detection algorithm.pdf:pdf},
isbn = {0-7803-7663-3},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Abrupt change detection,Kernel method,Music segmentation,Online,Single-class SVM},
number = {8},
pages = {2961--2974},
title = {{An online Kernel change detection algorithm}},
volume = {53},
year = {2005}
}
@book{Basseville1993,
abstract = {Over the last twenty years, there has been a significant increase in the number of real problems concerned with questions such as fault detection and diagnosis (monitoring); condition-based maintenance of industrial processes; safety of complex systems (aircrafts, boats, rockets, nuclear power plants, chemical technological processes, etc.); quality control; prediction of natural catastrophic events (earthquakes, tsunami, etc.); monitoring in biomedicine.},
author = {Basseville, M and Nikiforov, Igor V},
doi = {10.1016/0967-0661(94)90196-1},
file = {:Users/matt/Documents/Mendeley Desktop/Basseville, Nikiforov - 1993 - Detection of Abrupt Changes Theory and Application.pdf:pdf},
isbn = {0-13-126780-9},
issn = {09670661},
title = {{Detection of Abrupt Changes: Theory and Application}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.6896{\&}rep=rep1{\&}type=pdf},
year = {1993}
}
@article{Sing2005,
author = {Sing, T. and Sander, O. and Beerenwinkel, N. and Lengauer, T.},
doi = {10.1093/bioinformatics/bti623},
file = {:Users/matt/Documents/Mendeley Desktop/Sing et al. - 2005 - ROCR visualizing classifier performance in R.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {oct},
number = {20},
pages = {3940--3941},
publisher = {Oxford University Press},
title = {{ROCR: visualizing classifier performance in R}},
url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bti623},
volume = {21},
year = {2005}
}
@article{Tartakovsky2006,
abstract = {Sequential multi-chart detection procedures for detecting changes in multichannel sensor systems are developed. In the case of complete information on pre-change and post-change distributions, the detection algorithm represents a likelihood ratio-based multichannel generalization of Page's cumulative sum (CUSUM) test that is applied to general stochastic models that may include correlated and nonstationary observations. There are many potential application areas where it is necessary to consider multichannel generalizations and general statistical models. In this paper our main motivation for doing so is network security: rapid anomaly detection for an early detection of attacks in computer networks that lead to changes in network traffic. Moreover, this kind of application encourages the development of a nonparametric multichannel detection test that does not use exact pre-change (legitimate) and post-change (attack) traffic models. The proposed nonparametric method can be effectively applied to detect a wide variety of attacks such as denial-of-service attacks, worm-based attacks, port-scanning, and man-in-the-middle attacks. In addition, we propose a multichannel CUSUM procedure that is based on binary quantized data; this procedure turns out to be more efficient than the previous two algorithms in certain scenarios. All proposed detection algorithms are based on the change-point detection theory. They utilize the thresholding of test statistics to achieve a fixed rate of false alarms, while allowing changes in statistical models to be detected "as soon as possible". Theoretical frameworks for the performance analysis of detection procedures, as well as results of Monte Carlo simulations for a Poisson example and results of detecting real flooding attacks, are presented. ?? 2006.},
author = {Tartakovsky, Alexander G. and Rozovskii, Boris L. and Bla{\v{z}}ek, Rudolf B. and Kim, Hongjoong},
doi = {10.1016/j.stamet.2005.05.003},
file = {:Users/matt/Documents/Mendeley Desktop/Tartakovsky et al. - 2006 - Detection of intrusions in information systems by sequential change-point methods.pdf:pdf},
isbn = {1572-3127},
issn = {15723127},
journal = {Statistical Methodology},
keywords = {Change-point detection,Cumulative sum,Denial of service,Intrusion detection,Multichannel information systems,Page's test,Rapid detection,Sequential tests},
number = {3},
pages = {252--293},
title = {{Detection of intrusions in information systems by sequential change-point methods}},
volume = {3},
year = {2006}
}
@article{Tartakovsky2005,
abstract = {An efficient sequential nonparametric multi- chart (multichannel) CUSUM-type detection test for detecting changes in multichannel sensor systems is proposed. While there is a wide spectrum of applications where it is necessary to consider multichannel generalizations and general statistical models in change-point detection problems, the study in this pa- per is motivated by network security. Many kinds of intrusions in computer networks lead to abrupt changes in network traffic. These changes have to be detected as rapidly as possible while maintaining a false alarm rate at a low level. Computer intru- sion detection encourages the development of a nonparametric multichannel change-point detection test that does not use exact legitimate (pre-change) and attack (post-change) traffic models. The proposed nonparametric detection procedure can be effec- tively applied to detect a wide variety of attacks such as exter- nal denial of service attacks, worm based attacks, port scanning, and insider man-in-the-middle attacks. Operating characteris- tics of the proposed multichannel CUSUMtest are evaluated for real denial of service attacks using traces recently collected by CAIDA. The results of a comparison with a conventional single- channel CUSUM algorithm show that the multichannel test has much better performance.},
author = {Tartakovsky, Alexander G and Rozovskii, Boris L},
file = {:Users/matt/Documents/Mendeley Desktop/Tartakovsky, Rozovskii - 2005 - A Nonparametric Multichart CUSUM Test for Rapid Intrusion Detection.pdf:pdf},
journal = {Proceedings of Joint Statistical Meetings},
keywords = {change detection,computer intrusion detection,denial of service attacks,multichart cusum tests},
pages = {7--11},
title = {{A Nonparametric Multichart CUSUM Test for Rapid Intrusion Detection}},
year = {2005}
}
@article{Bersimis2007,
abstract = {In this paper we discuss the basic procedures for the implementation of multivariate statistical process control via control charting. Furthermore, we review multivariate extensions for all kinds of univariate control charts, such as multivariate Shewhart- type control charts, multivariate CUSUM control charts and multivariate EWMA control charts. In addition, we review unique procedures for the construction of multivariate control charts, based on multivariate statistical techniques such as principal components analysis (PCA) and partial least squares (PLS). Finally, we describe the most significant methods for the interpretation of an out-of-control signal.},
author = {Bersimis, S. and Psarakis, S. and Panaretos, J.},
doi = {10.1002/qre.829},
file = {:Users/matt/Documents/Mendeley Desktop/Bersimis, Psarakis, Panaretos - 2007 - Multivariate statistical process control charts An overview.pdf:pdf},
isbn = {0748-8017},
issn = {07488017},
journal = {Quality and Reliability Engineering International},
keywords = {CUSUM,EWMA,Hotelling's T2,Multivariate statistical process control,PCA,PLS,Process control,Quality control},
number = {5},
pages = {517--543},
title = {{Multivariate statistical process control charts: An overview}},
volume = {23},
year = {2007}
}
@manual{RCoreTeam2017,
abstract = {R Development Core Team (2011). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL http://www.R-project.org/.},
address = {Vienna, Austria},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{R Core Development Team}},
booktitle = {Document freely available on the internet at: http://www. r-project. org},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {3-900051-07-0},
issn = {1098-6596},
organization = {R Foundation for Statistical Computing},
pmid = {25246403},
title = {{R: a language and environment for statistical computing, 3.2.1}},
url = {https://www.r-project.org/},
year = {2015}
}
@article{Downey2008,
abstract = {We propose an algorithm for simultaneously detecting and locating changepoints in a time series, and a framework for predicting the distribution of the next point in the series. The kernel of the algorithm is a system of equations that computes, for each index i, the probability that the last (most recent) change point occurred at i. We evaluate this algorithm by applying it to the change point detection problem and comparing it to the generalized likelihood ratio (GLR) algorithm. We find that our algorithm is as good as GLR, or better, over a wide range of scenarios, and that the advantage increases as the signal-to-noise ratio decreases.},
archivePrefix = {arXiv},
arxivId = {0812.1237},
author = {Downey, Allen B.},
eprint = {0812.1237},
file = {:Users/matt/Documents/Mendeley Desktop/Downey - 2008 - A novel changepoint detection algorithm.pdf:pdf},
journal = {Applied Microbiology and Biotechnology},
pages = {1--11},
title = {{A novel changepoint detection algorithm}},
url = {http://arxiv.org/abs/0812.1237},
year = {2008}
}
